<p align="center">
  <h1 align="center">NoPo3DFusion: Scaling Two Images to Long Videos <br> via 3D-Aware Iterative Diffusion</h1>
  <p align="center">
    <a href="https://github.com/maxShen701">Xiaolong Shen</a>
    &nbsp;·&nbsp;
    <a href="https://chengzhag.github.io/">Cheng Zhang</a>
    &nbsp;·&nbsp;
    <a href="https://donydchen.github.io/">Donny Y. Chen</a>
    &nbsp;·&nbsp;
    <a href="https://ttwong12.github.io/myself.html">Tien-Tsin Wong</a>
    &nbsp;·&nbsp;
    <a href="https://jianfei-cai.github.io/">Jianfei Cai</a>
  </p>
  <h3 align="center">AJCAI 2025 (Short Oral)</h3>
  <h3 align="center"><a href="https://link.springer.com/chapter/10.1007/978-981-95-4972-6_9">Paper</a> | <a href="https://github.com/maxShen701/NoPo3DFusion">Code</a> </h3>
</p>

## Environment
Follow the official environment guides of [NoPoSplat](https://github.com/cvg/NoPoSplat?tab=readme-ov-file#installation) and [CogVideoX](https://github.com/zai-org/CogVideo?tab=readme-ov-file#diffusers), then install core dependencies via:

```bash
# Create conda env (Python 3.10 recommended)
conda create -n nopo3 python=3.10
conda activate nopo3
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```


## Dataset
1. Use the **RE10K dataset** (same data structure as NoPoSplat).
2. Organize the dataset into the `re10k/` folder in the project root:
   ```
   re10k/
   ├── train/        
   │   ├── 000001.torch/          
   │   ├── 000002.torch/
   │   ├── ...
   │   └── index.json
   └── test
   ```
3. Download RE10K from its [official website](https://google.github.io/real-estate-10k/) or NoPoSplat’s dataset guide.


## Model weight
Manually download pre-trained weights and place them in the following paths:

| Component                | Target Path                          | Download Source                          |
|--------------------------|--------------------------------------|------------------------------------------|
| NoPoSplat (RE10K)        | `noposplat/pretrained_weights/re10k.ckpt` |  [Hugging Face](https://huggingface.co/botaoye/NoPoSplat/tree/main)           |
| CogVideoX-5b-I2V         | `model_weight/CogVideoX-5b-I2V/`     | [Hugging Face](https://huggingface.co/THUDM/CogVideoX-5b-I2V) |
| Fine-tuned Transformer   | `model_weight/fine-tuned_tran/`      | (TBD)             |


## Requirement
- **Inference**: Run the script directly to generate novel view videos.  
  Command: `sh test.sh`  
  VRAM Requirement: Less than 20G  

- **Training**: Run the script to train the model (based on RE10K dataset).  
  Command: `sh train.sh`  
  VRAM Requirement: 80G (suggested for stable training)

## Example Output
Here are sample novel view videos generated by NoPo3DFusion:
- `examples/re10k.mp4`: Video of an indoor building scene from RE10K, generated via its original camera trajectory.
- `examples/acid.mp4`: Video of an outdoor scene from ACID, generated via its original camera trajectory.


## BibTeX

If you find our work helpful, please consider citing:

```bibtex
@inproceedings{shen2025nopo3dfusion,
  title={NoPo3DFusion: Scaling Two Images to Long Videos via 3D-Aware Iterative Diffusion},
  author={Shen, Xiaolong and Zhang, Cheng and Chen, Donny Y and Wong, Tien-Tsin and Cai, Jianfei},
  booktitle={Australasian Joint Conference on Artificial Intelligence},
  pages={109--120},
  year={2025},
  organization={Springer}
}
```

## Acknowledgements

This project is developed with several fantastic repos: [NoPoSplat](https://github.com/cvg/NoPoSplat), [CogVideoX](https://github.com/zai-org/CogVideo) and [MVSplat360](https://github.com/donydchen/mvsplat360). We thank the original authors for their excellent work.
